--- 
title_meta  : Chapter 6
title       : More on Data Frames
description : Most data sets you will be working with will be stored as a data frame. Learn data frame operations will help your data analysis procedure.


--- type:NormalExercise lang:r xp:100 skills:1 key:f625f0fd8d
## Filtering Data Frames Using subset()

Filtering means extracting rows from a data frame that satisfy a logical condition, Data frames can be ﬁltered using boolean vectors and brackets "[]" operators, The function subset() ﬁlters data frames, by applying logical conditions to its columns, using the column names, subset() provides a succinct notation and discards NA values, but it’s slightly slower than using boolean vectors and brackets "[]" operators.


*** =instructions
- Use `subset()` to filter dataframe.

*** =hint
Follow the instruction and introduction. 

*** =pre_exercise_code
```{r}
```

*** =sample_code

```{r}
# load the package microbenchmark


# filter airquality


# filter airquality by subset


# use microbenchmark to compare speed

```

*** =solution
```{r}
# load the package microbenchmark
library(microbenchmark)

# filter airquality
airquality[(airquality$Solar.R>320 &
        !is.na(airquality$Solar.R)), ]

# filter airquality by subset
subset(x=airquality, subset=(Solar.R>320))

# use microbenchmark to compare speed
summary(microbenchmark(
    subset=subset(x=airquality, subset=(Solar.R>320)),
    brackets=airquality[(airquality$Solar.R>320 &
            !is.na(airquality$Solar.R)), ],
times=10))[, c(1, 4, 5)]
```

*** =sct
```{r}
test_error()
success_msg("Yes! Now you know how to deal with a function!")
```
--- type:NormalExercise lang:r xp:100 skills:1 key:d4ddcf9a7d
## Splitting Data Frames Using factor Categorical Variables

The function split() divides an object into a list of objects, according to a factor (categorical variable), The list’s names attribute is equal to the factor level.

*** =instructions
- Split the dataframe according to factor. Use the Iris dataframe.

*** =hint
Follow the instruction and introductions.

*** =pre_exercise_code
```{r}
# no pec
```

*** =sample_code
```{r}
# Species has three distinct values


# Create separate data frame for setosa frames by hand according to Species


# Create separate data frame for versicolor by hand according to Species


# Create separate data frame for virginica by hand according to Species


# get the dimension of new dataframe about setosa


# get the first two rows of new setosa dataframe

```

*** =solution
```{r}
# Species has three distinct values
unique(iris$Species)

# Create separate data frame for setosa frames by hand according to Species
set_osa <- iris[iris$Species=="setosa", ]

# Create separate data frame for versicolor by hand according to Species
versi_color <- iris[iris$Species=="versicolor", ]

# Create separate data frame for virginica by hand according to Species
virgin_ica <- iris[iris$Species=="virginica", ]

# get the dimension of new dataframe about setosa
dim(set_osa)

# get the first two rows of new setosa dataframe
head(set_osa, 2)
```

*** =sct
```{r}
test_error()
success_msg("Wonderful!")
```


--- type:NormalExercise lang:r xp:100 skills:1 key:c8f389fdbd
## The split-apply-combine Procedure Example

The split-apply-combine procedure consists of: dividing an object into a list, according to a factor (attribute), applying a function to each list element, combining the results.

The split-apply-combine procedure is similar to pivot tables in Excel, The split-apply-combine procedure, by Hadley Wickham: (http://www.jstatsoft.org/v40/i01/paper)

The split-apply-combine procedure can be performed through successive applications of functions split(), apply(), and unlist().

The aggregate() functional performs the split-apply-combine procedure, by applying a function to groups of an object, aggregate() returns a data frame containing the names of the groups.

*** =instructions
- Conduct split-apply-aggregate on mtcars dataset

*** =hint
Remember we learnt `split()` for split procedure, the `*apply()` family for apply and we use `aggregate()` for aggregation.

*** =pre_exercise_code
```{r}
# no pec
```

*** =sample_code
```{r}
# split iris into list based on Species


# have a look to the structure of splitted dataframe


# get the name attributes


# get the dimension attributes


# get the first two rows


# cyl has three unique values


# split mtcars data frame based on number of cylinders


# have a look to the structure of splitted dataframe


# get the name attributes


# mean mpg for each cylinder group


# function aggregate() performs split-apply-combine


# aggregate() all columns

```

*** =solution
```{r}
# split iris into list based on Species
split_iris <- split(iris, iris$Species)

# have a look to the structure of splitted dataframe
str(split_iris, max.level=1)

# get the name attributes
names(split_iris)

# get the dimension attributes
dim(split_iris$setosa)

# get the first two rows
head(split_iris$setosa, 2)

# cyl has three unique values
unique(mtcars$cyl)

# split mtcars data frame based on number of cylinders
split_cars <- split(mtcars, mtcars$cyl)

# have a look to the structure of splitted dataframe
str(split_cars, max.level=1)

# get the name attributes
names(split_cars)

# mean mpg for each cylinder group
unlist(lapply(split_cars, function(x) mean(x$mpg)))

# function aggregate() performs split-apply-combine
aggregate(formula=(mpg ~ cyl), data=mtcars, FUN=mean)

# aggregate() all columns
aggregate(x=mtcars, by=list(cyl=mtcars$cyl), FUN=mean)
```

*** =sct
```{r}
success_msg("Nice work!")
```


--- type:NormalExercise lang:r xp:100 skills:1 key:f09c0189ac
## The tapply() Functional

The `tapply()` functional is a specialized version of the `apply()` functional, that applies a function to elements of a jagged array, A jagged array is a list consisting of elements which are vectors (or matrices) of diﬀerent lengths, `tapply()` accepts a vector of values "X", a factor "INDEX", and a function "FUN", `tapply()` ﬁrst groups the elements of "X" according to the factor "INDEX", transforming it into a jagged array, and then applies "FUN" to each element of the jagged array, `tapply()` applies a function to sub-vectors aggregated using a factor, and performs the whole split-apply-combine procedure in a single function call, The `by()` function is a wrapper for `tapply()`, The `with()` function evaluates an expression in an environment constructed from the data

*** =instructions
- Use `tapply()` to finish the split-apply-combine process altogether!

*** =hint
Carefully follow the instruction and introduction. Also you can use `?tapply()` for more information and examples.

*** =pre_exercise_code
```{r}
# no pec
```

*** =sample_code
```{r}
# mean mpg for each cylinder group


# using with() environment


# function sapply() instead of tapply()


# function by() instead of tapply()

```

*** =solution
```{r}
# mean mpg for each cylinder group
tapply(X=mtcars$mpg, INDEX=mtcars$cyl, FUN=mean)

# using with() environment
with(mtcars, tapply(X=mpg, INDEX=cyl, FUN=mean))

# function sapply() instead of tapply()
with(mtcars,
     sapply(sort(unique(cyl)), function(x) {
       structure(mean(mpg[x==cyl]), names=x)
       }, USE.NAMES=TRUE))

# function by() instead of tapply()
with(mtcars, by(data=mpg, INDICES=cyl, FUN=mean))
```

*** =sct
```{r}
success_msg("Great job!")
```

--- type:NormalExercise lang:r xp:100 skills:1 key:7090dc3538
## The split-apply-combine Returning Matrices Example

Sometimes the split-apply-combine procedure returns a list of vectors, A list of vectors can be ﬂattened into a matrix using the functions `do.call()` and either `rbind()` or `cbind()`, The function `do.call()` executes a function call using a function name and a list of arguments, do.call() passes the list elements individually, instead of passing the whole list as one argument: 

````
do.call(fun, list)= fun(list[[1]], list[[2]], ...)
````

*** =instructions
- Use split-apply-combine to flatten returned results.

*** =hint
Follow the instruction and introduction!

*** =pre_exercise_code
```{r}
# no pec
split_cars <- split(mtcars, mtcars$cyl)
```

*** =sample_code
```{r}
# get several mpg stats for each cylinder group
data_cars <- sapply(split_cars,
      function(x) {
        c(mean=mean(x$mpg), max=max(x$mpg), min=min(x$mpg))
      }
      )

# sapply produces a matrix


# now same using lapply with anonymous function


# lapply produces a list


# do.call flattens list into a matrix

```

*** =solution
```{r}
# get several mpg stats for each cylinder group
data_cars <- sapply(split_cars,
      function(x) {
        c(mean=mean(x$mpg), max=max(x$mpg), min=min(x$mpg))
      }
      )

# sapply produces a matrix
data_cars

# now same using lapply with anonymous function
data_cars <- lapply(split_cars,
      function(x) {
        c(mean=mean(x$mpg), max=max(x$mpg), min=min(x$mpg))
      }
      )

# lapply produces a list
is.list(data_cars)

# do.call flattens list into a matrix
do.call(cbind, data_cars)
```

*** =sct
```{r}
success_msg("That looks more beautiful! Head over to the next exercise.")
```


--- type:NormalExercise lang:r xp:100 skills:1 key:a80ae7fbe8
## Benchmarking the Speed of R Code

The function system.time() calculates the execution time (in seconds) used to evaluate a given expression, system.time() returns the ”user time” (execution time of user instructions), the ”system time” (execution time of operating system calls), and ”elapsed time” (total execution time, including system latency waiting), The function microbenchmark() from package microbenchmark calculates and compares the execution time of R expressions (in milliseconds), and is more accurate than system.time(), microbenchmark() executes the expression many times, and returns the distribution of total execution times.

*** =instructions
- Test the speed to certain code with microbenchmark

*** =hint
Follow the instruction and introduction.

*** =pre_exercise_code
```{r}
# no pec
```

*** =sample_code
```{r}
# import microbenchmark package


# create vector
foo <- runif(1e6)

# lock time for single operation


# compare time for different operations

```

*** =solution
```{r}
# import microbenchmark package
library(microbenchmark)

# create vector
foo <- runif(1e6)

# lock time for single operation
system.time(foo^0.5)

# compare time for different operations
microbenchmark(sqrt(foo), foo^0.5, times=10)
```

*** =sct
```{r}
success_msg("Nice one! This is going fast!")
```
--- type:NormalExercise lang:r xp:100 skills:1 key:b6125af738
## Writing Fast R Code Using Compiled Functions

Compiled functions directly call compiled C++ or Fortran code, which performs the calculations and returns the result back to R, This makes compiled functions much faster than interpreted functions, which have to be parsed by R, `sum()` is much faster than mean(), because `sum()` is a compiled function, while `mean()` is an interpreted function, Given a single argument, any() is equivalent to %in%, but is much faster because it’s a compiled function, %in% is a wrapper for match() deﬁned as follows: `"%in%" <- function(x, table) match(x, table, nomatch=0) > 0`.

*** =instructions
- Compare the speed of complied and uncompiled functions.

*** =hint
Follow the instruction and introductions. Be careful that to see information about a function you can't add `()` after function name.

*** =pre_exercise_code
```{r}
library(microbenchmark)
```

*** =sample_code
```{r}
# sum() is a compiled primitive function


# mean() is a generic function


# create large vector


# change code, sum() is much faster than mean()
summary(
  (sum(foo), mean(foo), times=10)
  )[, c(1, 4, 5)]

# any() is a compiled primitive function


# any() is much faster than %in% wrapper for match()

```

*** =solution
```{r}
# sum() is a compiled primitive function
sum

# mean() is a generic function
mean

# create large vector
foo <- runif(1e6)

# change code, sum() is much faster than mean()
summary(
  microbenchmark(sum(foo), mean(foo), times=10)
  )[, c(1, 4, 5)]

# any() is a compiled primitive function
any

# any() is much faster than %in% wrapper for match()
summary(
  microbenchmark(any(foo == 1), {1 %in% foo}, times=10)
  )[, c(1, 4, 5)]
```

*** =sct
```{r}
success_msg("Great!")
```

--- type:NormalExercise lang:r xp:100 skills:1 key:7aa0a94261
## Writing Fast R Code Without Method Dispatch

As a general rule, calling generic functions is slower than directly calling individual methods, because generic functions must execute extra R code for method dispatch, The generic function as.data.frame() coerces matrices and other objects into data frames, The method `as.data.frame.matrix()` coerces only matrices into data frames, `as.data.frame.matrix()` is about 50% faster than `as.data.frame()`, because it skips extra R code in `as.data.frame()` needed for argument validation, error checking, and method dispatch, Users can create even faster functions of their own by extracting only the essential R code into their own specialized functions, ignoring R code needed to handle diﬀerent types of data, Such specialized functions are faster but less ﬂexible, so they may fail with diﬀerent types of data.


*** =instructions
- Skip the method dispatch procedure to speed up your code!

*** =hint
Follow the instruction and introduction.

*** =pre_exercise_code
```{r}

```

*** =sample_code
```{r}
# load microbenchmark package


# create matrix
mat_rix <- matrix(1:9, ncol=3,
  dimnames=list(paste0("row", 1:3),
          paste0("col", 1:3)))

# change the code to create specialized function
matrix_to_dframe <- function(mat_rix) {
  n_col <- ncol(mat_rix)
  dframe <- vector("list", 2)
  for(in_dex in 1:n_col)
    dframe <- mat_rix[, in_dex]
  attr(dframe, "row.names") <-
    .set_row_names(row(mat_rix))
  attr(dframe, "class") <- "data.frame"
  dframe
}

# compare speed of three methods

```

*** =solution
```{r}
# load microbenchmark package
library(microbenchmark)

# create matrix
mat_rix <- matrix(1:9, ncol=3,
  dimnames=list(paste0("row", 1:3),
          paste0("col", 1:3)))

# change the code to create specialized function
matrix_to_dframe <- function(mat_rix) {
  n_col <- ncol(mat_rix)
  dframe <- vector("list", n_col)
  for(in_dex in 1:n_col)
    dframe <- mat_rix[, in_dex]
  attr(dframe, "row.names") <-
    .set_row_names(NROW(mat_rix))
  attr(dframe, "class") <- "data.frame"
  dframe
}

# compare speed of three methods
summary(microbenchmark(
  matrix_to_dframe(mat_rix),
  as.data.frame.matrix(mat_rix),
  as.data.frame(mat_rix),
  times=10))[, c(1, 4, 5)]
```

*** =sct
```{r}
success_msg("Great! Continue to the next exercise and discover yet another way of subsetting!")
```


--- type:NormalExercise lang:r xp:100 skills:1 key:d6245c1bb1
## Using apply() Instead of for() and while() Loops

All the diﬀerent R loops have similar speed, with `apply()` the fastest, then `vapply()`, `lapply()` and `sapply()` slightly slower, and `for()` loops the slowest.

More importantly, the `apply()` syntax is more readable and concise, and ﬁts the functional language paradigm of R, so is therefore preferred obver `for()` loops, Both `vapply()` and `lapply()` are compiled (primitive) functions, and therefore can be faster than other `apply()` functions

*** =instructions
- Compare speed of `*apply()` family and `for()`

*** =hint
Avoid `for()` loop in R.


*** =pre_exercise_code
```{r}
library(microbenchmark)
```

*** =sample_code
```{r}
# matrix with 5,000 rows
big_matrix <- matrix(rnorm(10000), ncol=2)

# allocate memory for row sums


# change the code to compare speed of *apply() family and for() loop
summary(microbenchmark(
  ap_ply=apply(big_matrix, 1, sum),
  l_apply=apply(1:NROW(big_matrix), function(in_dex)
    sum(big_matrix[in_dex, ])),
  v_apply=apply(1:NROW(big_matrix), function(in_dex)
    sum(big_matrix[in_dex, ]),
    FUN.VALUE=c(sum=0)),
  s_apply=apply(1:NROW(big_matrix), function(in_dex)
    sum(big_matrix[in_dex, ])),
  for_loop=for(i in 1:NROW(big_matrix)) {
    row_sums[i] <- sum(big_matrix[in_dex,])
  },
  ))[, c(1, 4, 5)]
```

*** =solution
```{r}
# matrix with 5,000 rows
big_matrix <- matrix(rnorm(10000), ncol=2)

# allocate memory for row sums
row_sums <- numeric(NROW(big_matrix))

# change the code to compare speed of *apply() family and for() loop
summary(microbenchmark(
  ap_ply=apply(big_matrix, 1, sum),
  l_apply=lapply(1:NROW(big_matrix), function(in_dex)
    sum(big_matrix[in_dex, ])),
  v_apply=vapply(1:NROW(big_matrix), function(in_dex)
    sum(big_matrix[in_dex, ]),
    FUN.VALUE=c(sum=0)),
  s_apply=sapply(1:NROW(big_matrix), function(in_dex)
    sum(big_matrix[in_dex, ])),
  for_loop=for(i in 1:NROW(big_matrix)) {
    row_sums[i] <- sum(big_matrix[i,])
  },
  times=10))[, c(1, 4, 5)]
```

*** =sct
```{r}
success_msg("Nice work!")
```


--- type:NormalExercise lang:r xp:100 skills:1 key:c1a08e245c
## Increasing Speed of Loops by Pre-allocating Memory

R doesn’t require allocating memory for new vectors or lists, allowing for them to ”grow” each time a new element is added, R allows assigning a value to a vector element that doesn’t exist yet (hasn’t been allocated), But when R creates a bigger object from an existing one, it ﬁrst allocates memory for the new object, and then copies the existing values to the new memory, which is very memory intensive and slow, Using the functions `c()`, `append()`, `cbind()`, `rbind()`, and `paste()` to append data to objects is even slower than vector assignment, Adding elements to a vector in a loop is very slow, and therefore not recommended, Pre-allocating memory for large vectors before performing loops increases their speed, The function `numeric(k)` returns a numeric vector of zeros of length k, `numeric(0)` returns an empty (zero length) numeric vector (not to be confused with a NULL.

*** =instructions
- Pre-allocate memory to speed up loop.

*** =hint
Follow the instruction and introduction.

*** =pre_exercise_code
```{r}
library(microbenchmark)
```

*** =sample_code
```{r}
# create big vector
big_vector <- rnorm(5000)

# change the code, allocate full memory for cumulative sum
summary(microbenchmark(
  for_loop={cum_sum <- numeric(length(big_vector))
    cum_sum[1] <- big_vector[1]
    for(i in 1:length(big_vector)) {
      cum_sum[i] <- cum_sum[i] + big_vector[i]
    }},
  grow_vec={cum_sum <- numeric(k)
    cum_sum[1] <- big_vector[1]
    for(i in 1:length(big_vector)) {
      cum_sum[i] <- cum_sum[i] + big_vector[i]
    }},
  com_bine={cum_sum <- numeric(k)
    cum_sum[1] <- big_vector[1]
    for(i in 1:length(big_vector)) {
      cum_sum <- c(cum_sum, big_vector[i])
    }},
  ))[, c(1, 4, 5)]
```

*** =solution
```{r}
# create big vector
big_vector <- rnorm(5000)

# change the code, allocate full memory for cumulative sum
summary(microbenchmark(
  for_loop={cum_sum <- numeric(length(big_vector))
    cum_sum[1] <- big_vector[1]
    for(i in 2:length(big_vector)) {
      cum_sum[i] <- cum_sum[i-1] + big_vector[i]
    }},
  grow_vec={cum_sum <- numeric(0)
    cum_sum[1] <- big_vector[1]
    for(i in 2:length(big_vector)) {
      cum_sum[i] <- cum_sum[i-1] + big_vector[i]
    }},
  com_bine={cum_sum <- numeric(0)
    cum_sum[1] <- big_vector[1]
    for(i in 2:length(big_vector)) {
      cum_sum <- c(cum_sum, big_vector[i])
    }},
  times=10))[, c(1, 4, 5)]
```

*** =sct
```{r}
success_msg("Great! Pre-allocation is a lot faster than growing memory at every cycle, this principle applies to other programming language as well.")
```


--- type:NormalExercise lang:r xp:100 skills:1 key:e9ca3eeb99
## Vectorized Functions for Vector Computations

Vectorized functions accept vectors as their arguments, and return a vector of the same length as their value, Many vectorized functions are also compiled (they pass their data to compiled C++ code), which makes them very fast, The following vectorized compiled functions calculate cumulative values over large vectors: 
````
cummax(),
cummin(),
cumsum(),
cumprod()
````
Standard arithmetic operations ("+", "-", etc.) can be applied to vectors, and are implemented as vectorized compiled functions, ifelse() and which() are vectorized compiled functions for logical operations, But many vectorized functions perform their calculations in R code, and are therefore slow, but convenient to use.

*** =instructions
- Utilize the vectorized compiled function to greatly enhance your speed.

*** =hint
Follow the instruction and introductions.

*** =pre_exercise_code
```{r}
library(microbenchmark)
```

*** =sample_code
```{r}
# create large vectors
vec_tor1 <- rnorm(1000000)
vec_tor2 <- rnorm(1000000)
big_vector <- numeric(1000000)

# sum vectors using "for" loop

# sum vectors using vectorized "+"


# allocate memory for cumulative sum


# set the value for the starting element


# cumulative sum using "for" loop


# cumulative sum using "cumsum"

```

*** =solution
```{r}
# create large vectors
vec_tor1 <- rnorm(1000000)
vec_tor2 <- rnorm(1000000)
big_vector <- numeric(1000000)

# sum vectors using "for" loop
system.time(
  for(i in 1:length(vec_tor1)) {
    big_vector[i] <- vec_tor1[i] + vec_tor2[i]
  }
)

# sum vectors using vectorized "+"
system.time(big_vector <- vec_tor1 + vec_tor2)

# allocate memory for cumulative sum
cum_sum <- numeric(length(big_vector))

# set the value for the starting element
cum_sum[1] <- big_vector[1]

# cumulative sum using "for" loop
system.time(
  for(i in 2:length(big_vector)) {
    cum_sum[i] <- cum_sum[i-1] + big_vector[i]
  }
)

# cumulative sum using "cumsum"
system.time(cum_sum <- cumsum(big_vector))
```

*** =sct
```{r}
success_msg("Nice one!")
```


--- type:NormalExercise lang:r xp:100 skills:1 key:8e5ade7078
## Vectorized Functions for Matrix Computations

`apply()` loops are very ineﬃcient for calculating statistics over rows and columns of very large matrices, R has very fast vectorized compiled functions for calculating sums and means of rows and columns: 
````
rowSums(),
colSums(),
rowMeans(),
colMeans()
````
These vectorized functions are also compiled functions, so they’re very fast because they pass their data to compiled C++ code, which performs the loop calculations

*** =instructions
- Utilize compiled functions dedicated for matrix to save additional time. Compare their speed with `*apply()` family.

*** =hint
Follow the instruction and introductions.

*** =pre_exercise_code
```{r}
# no pec
library(microbenchmark)
```

*** =sample_code
```{r}
# matrix with 5,000 rows
big_matrix <- matrix(rnorm(10000), ncol=2)

# calculate row sums two different ways

```

*** =solution
```{r}
# matrix with 5,000 rows
big_matrix <- matrix(rnorm(10000), ncol=2)

# calculate row sums two different ways
summary(microbenchmark(
  row_sums=rowSums(big_matrix),
  ap_ply=apply(big_matrix, 1, sum),
  times=10))[, c(1, 4, 5)]
```

*** =sct
```{r}
success_msg("Great!")
```


--- type:NormalExercise lang:r xp:100 skills:1 key:ec87541ef1
## Fast R Code for Matrix Computations

The functions `pmax()` and `pmin()` calculate the ”parallel” maxima (minima) of multiple vector arguments, `pmax()` and `pmin()` return a vector, whose n-th element is equal to the maximum (minimum) of the n-th elements of the arguments, with shorter vectors recycled if necessary, `pmax.int()` and `pmin.int()` are methods of generic functions `pmax()` and `pmin()`, designed for atomic vectors, `pmax()` can be used to quickly calculate the maximum values of rows of a matrix, by ﬁrst converting the matrix columns into a list, and then passing them to `pmax()`, `pmax.int()` and `pmin.int()` are very fast because they are compiled functions (compiled from C++ code).


*** =instructions
- Use `pmax()` and `pmin()` family to search through the matrix.

*** =hint
Follow the instruction and introduction.

*** =pre_exercise_code
```{r}
big_matrix <- matrix(rnorm(10000), ncol=2)
```

*** =sample_code
```{r}
# load the microbenchmark package


# see the structure of pmax function


# calculate row maximums two different ways
summary(microbenchmark(
  p_max=
    do.call(pmax.int,big_matrix),
  l_apply=
    lapply(seq_along(big_matrix[, 1]),
  function(in_dex) max(big_matrix[in_dex, ])),
  times=10)[, c(1, 4, 5)]
```

*** =solution
```{r}
# load the microbenchmark package
library(microbenchmark)

# see the structure of pmax function
str(pmax)

# calculate row maximums two different ways
summary(microbenchmark(
  p_max=
    do.call(pmax.int,
lapply(seq_along(big_matrix[1, ]),
  function(in_dex) big_matrix[, in_dex])),
  l_apply=unlist(
    lapply(seq_along(big_matrix[, 1]),
  function(in_dex) max(big_matrix[in_dex, ]))),
  times=10))[, c(1, 4, 5)]
```

*** =sct
```{r}
success_msg("Wonderful!")
```


--- type:NormalExercise lang:r xp:100 skills:1 key:3d8a9618b9
## Package matrixStats for Fast Matrix Computations

The package matrixStats contains functions for calculating aggregations over matrix columns and rows, and other matrix computations, such as: estimating location and scale: `rowRanges()`, `colRanges()`, and `rowMaxs()`, `rowMins()`, etc., testing and counting values: `colAnyMissings()`, `colAnys()`, etc., cumulative functions: `colCumsums()`, `colCummins()`, etc., binning and diﬀerencing: `binCounts()`, `colDiffs()`, etc.

A summary of matrixStats functions can be found under: "https://cran.r-project.org/web/packages/matrixStats/ vignettes/matrixStats-methods.html"

The matrixStats functions are very fast because they are compiled functions (compiled from C++ code)

*** =instructions
- Explore the functions in `matrixStats` package.

*** =hint
Follow the instruction and introductions.

*** =pre_exercise_code
```{r}
# no pec
library(microbenchmark)
big_matrix <- matrix(rnorm(10000), ncol=2)
```

*** =sample_code
```{r}
# load package matrixStats


# calculate row min values three different ways
summary(microbenchmark(
  row_mins=rowMins(big_matrix),
  p_min=
    do.call(pmin.int, big_matrix[, in_dex])),
  as_data_frame=
    do.call(pmin.int, big_matrix),
  ))[, c(1, 4, 5)]
```

*** =solution
```{r}
# load package matrixStats
library(matrixStats)

# calculate row min values three different ways
summary(microbenchmark(
  row_mins=rowMins(big_matrix),
  p_min=
    do.call(pmin.int,
      lapply(seq_along(big_matrix[1, ]),
             function(in_dex)
               big_matrix[, in_dex])),
  as_data_frame=
    do.call(pmin.int,
      as.data.frame.matrix(big_matrix)),
  times=10))[, c(1, 4, 5)]
```

*** =sct
```{r}
success_msg("Great!")
```


--- type:NormalExercise lang:r xp:100 skills:1 key:7b69825576
## Writing Fast R Code Using Vectorized Operations

R-style code is code that relies on vectorized compiled functions, instead of `for()` loops, `for()` loops in R are slow because they call functions multiple times, and individual function calls are compute-intensive and slow, The brackets `[]` operator is a vectorized compiled function, and is therefore very fast, Vectorized assignments using brackets `[]` and boolean or integer vectors to subset vectors or matrices are therefore preferable to `for()` loops, R code that uses vectorized compiled functions can be as fast as C++ code, R-style code is also very expressive, i.e. it allows performing complex operations with very few lines of code

*** =instructions
- Utilize vectorized operations.

*** =hint
Follow the instruction and introductions.

*** =pre_exercise_code
```{r}
# no pec
library(microbenchmark)
big_matrix <- matrix(rnorm(10000), ncol=2)
```

*** =sample_code
```{r}
# assign values to vector three different ways
summary(microbenchmark(

# fast vectorized assignment loop performed in C using brackets "[]"
  brack_ets={vec_tor <- numeric(10)
    vec_tor <- 2},
    
# slow because loop is performed in R
  for_loop={vec_tor <- numeric(10)
    for (in_dex in vec_tor)
      vec_tor[in_dex] <- 2},
      
# very slow because no memory is pre-allocated
# "vec_tor" is "grown" with each new element
  grow_vec={vec_tor <- numeric(0)
    for (in_dex in 1:10)
    
# add new element to "vec_tor" ("grow" it)
      vec_tor[in_dex] <- 2},
  times=10))[, c(1, 4, 5)]
```

*** =solution
```{r}
# assign values to vector three different ways
summary(microbenchmark(

# fast vectorized assignment loop performed in C using brackets "[]"
  brack_ets={vec_tor <- numeric(10)
    vec_tor[] <- 2},
    
# slow because loop is performed in R
  for_loop={vec_tor <- numeric(10)
    for (in_dex in seq_along(vec_tor))
      vec_tor[in_dex] <- 2},
      
# very slow because no memory is pre-allocated
# "vec_tor" is "grown" with each new element
  grow_vec={vec_tor <- numeric(0)
    for (in_dex in 1:10)
    
# add new element to "vec_tor" ("grow" it)
      vec_tor[in_dex] <- 2},
  times=10))[, c(1, 4, 5)]
```

*** =sct
```{r}
success_msg("The speed difference can be enormous!")
```


--- type:NormalExercise lang:r xp:100 skills:1 key:cd816481aa
## Vectorized Functions

Functions which use vectorized operations and functions are automatically vectorized themselves, Functions which only call other compiled C vectorized functions, are also very fast, But not all functions are vectorized, or they’re not vectorized with respect to their parameters, Some vectorized functions perform their calculations in R code, and are therefore slow, but convenient to use.


*** =instructions
- Utilize vectorized functions.

*** =hint
Follow the instruction and introductions.

*** =pre_exercise_code
```{r}
# no pec
library(microbenchmark)
```

*** =sample_code
```{r}
# define function vectorized automatically
my_fun <- function(in_put, pa_ram) {
  pa_ram*in_put
}

# "in_put" is vectorized


# "pa_ram" is vectorized


# define vectors of parameters of rnorm()
std_devs <-
  structure(1:3, names=paste0("sd=", 1:3))
me_ans <-
  structure(-1:1, names=paste0("mean=", -1:1))

# "sd" argument of rnorm() isn't vectorized


# "mean" argument of rnorm() isn't vectorized

```

*** =solution
```{r}
# define function vectorized automatically
my_fun <- function(in_put, pa_ram) {
  pa_ram*in_put
}

# "in_put" is vectorized
my_fun(in_put=1:3, pa_ram=2)

# "pa_ram" is vectorized
my_fun(in_put=10, pa_ram=2:4)

# define vectors of parameters of rnorm()
std_devs <-
  structure(1:3, names=paste0("sd=", 1:3))
me_ans <-
  structure(-1:1, names=paste0("mean=", -1:1))

# "sd" argument of rnorm() isn't vectorized
rnorm(1, sd=std_devs)

# "mean" argument of rnorm() isn't vectorized
rnorm(1, mean=me_ans)
```

*** =sct
```{r}
success_msg("Flexibility of R code helps with vectorized functions!")
```


--- type:NormalExercise lang:r xp:100 skills:1 key:d8823d128f
## Performing sapply() Loops Over Function Parameters

Many functions aren’t vectorized with respect to their parameters, Performing `sapply()` loops over a function’s parameters produces vector output

*** =instructions
- Utilize `sapply()` for vectorized parameter input.

*** =hint
Follow the instruction and introductions.

*** =pre_exercise_code
```{r}
# no pec
std_devs <-
  structure(1:3, names=paste0("sd=", 1:3))
me_ans <-
  structure(-1:1, names=paste0("mean=", -1:1))
```

*** =sample_code
```{r}
# sapply produces desired vector output
set.seed(1121)
sapply(std_devs, function(std_dev) rnorm(n=2, sd=std_dev))

# reset seed


# vectorize on rnorm


# reset seed


# vectorize on rnorm


# reset seed


# vectorize on rnorm

```

*** =solution
```{r}
# sapply produces desired vector output
set.seed(1121)
sapply(std_devs, function(std_dev) rnorm(n=2, sd=std_dev))

# reset seed
set.seed(1121)

# vectorize on rnorm
sapply(std_devs, rnorm, n=2, mean=0)

# reset seed
set.seed(1121)

# vectorize on rnorm
sapply(me_ans, function(me_an) rnorm(n=2, mean=me_an))

# reset seed
set.seed(1121)

# vectorize on rnorm
sapply(me_ans, rnorm, n=2)
```

*** =sct
```{r}
success_msg("Applause for your continued performance!")
```


--- type:NormalExercise lang:r xp:100 skills:1 key:737ea4a5e4
## Creating Vectorized Functions

In order to vectorize a function with respect to one of its parameters, it’s necessary to perform a loop over it, The function `Vectorize()` performs an `apply()` loop over the arguments of a function, and returns a vectorized version of the function, `Vectorize()` vectorizes the arguments passed to "vectorize.args", `Vectorize()` is an example of a higher-order function: it accepts a function as its argument and returns a function as its value, Functions that are vectorized using `Vectorize()` or `apply()` loops are just as slow as `apply()` loops, but convenient to use

*** =instructions
- `Vectorize()` can also make your functions vectorized.

*** =hint
Follow the instruction and introductions. Assign vectorized function back to the same function name and input results to it.

*** =pre_exercise_code
```{r}
# no pec
std_devs <-
  structure(1:3, names=paste0("sd=", 1:3))
me_ans <-
  structure(-1:1, names=paste0("mean=", -1:1))
```

*** =sample_code
```{r}
# rnorm() vectorized with respect to "std_dev"
vec_rnorm <- function(n, mean=0, sd=1) {
  if (length(sd)==1)
    rnorm(n=n, mean=mean, sd=sd)
  else
    sapply(sd, rnorm, n=n, mean=mean)
}

# reset seed


# run unvectorized function


# rnorm() vectorized with respect to "mean" and "sd"
vec_rnorm 

# reset seed


# run vectorized function, change sd


# reset seed


# run vectorized function, change mean

```

*** =solution
```{r}
# rnorm() vectorized with respect to "std_dev"
vec_rnorm <- function(n, mean=0, sd=1) {
  if (length(sd)==1)
    rnorm(n=n, mean=mean, sd=sd)
  else
    sapply(sd, rnorm, n=n, mean=mean)
}

# reset seed
set.seed(1121)

# run unvectorized function
vec_rnorm(n=2, sd=std_devs)

# rnorm() vectorized with respect to "mean" and "sd"
vec_rnorm <- Vectorize(FUN=rnorm,
        vectorize.args=c("mean", "sd")
)

# reset seed
set.seed(1121)

# run vectorized function, change sd
vec_rnorm(n=2, sd=std_devs)

# reset seed
set.seed(1121)

# run vectorized function, change mean
vec_rnorm(n=2, mean=me_ans)
```

*** =sct
```{r}
success_msg("Use the Vectorize() and save more time!")
```


--- type:NormalExercise lang:r xp:100 skills:1 key:530c1e1c92
## The mapply() Functional

The `mapply()` functional is a multivariate version of `sapply()`, that allows calling a non-vectorized function in a vectorized way, `mapply()` accepts a multivariate function passed to the "FUN" argument and any number of vector arguments passed to the dots "...", `mapply()` calls "FUN" on the vectors passed to the dots "...", one element at a time:
````
mapply(FUN = fun,vec1,vec2,...) = [fun(vec1,1,vec2,1,...),..., fun(vec1,i,vec2,i,...),...]
````
`mapply()` passes the ﬁrst vector to the ﬁrst argument of "FUN", the second vector to the second argument, etc. The ﬁrst element of the output vector is equal to "FUN" called on the ﬁrst elements of the input vectors, the second element is "FUN" called on the second elements, etc.

The output of mapply() is a vector of length equal to the longest vector passed to the dots "..." argument, with the elements of the other vectors recycled if necessary.

*** =instructions
- Utilize `mapply()` on matrix.

*** =hint
Follow the instruction and introductions.

*** =pre_exercise_code
```{r}
# no pec
std_devs <-
  structure(1:3, names=paste0("sd=", 1:3))
me_ans <-
  structure(-1:1, names=paste0("mean=", -1:1))
```

*** =sample_code
```{r}
# get the structure of sum()


# na.rm is bound by name


# get the structure of rnorm


# mapply vectorizes both arguments "mean" and "sd"


# mapply vectorizes anonymous function


# rnorm() vectorized with respect to "mean" and "sd", dealing with single value as well
vec_rnorm <- function(n, mean=0, sd=1) {
    mapply(rnorm, n=n, mean=mean, sd=sd)
}

# call vec_rnorm() on vector of "sd"


# call vec_rnorm() on vector of "mean"

```

*** =solution
```{r}
# get the structure of sum()
str(sum)

# na.rm is bound by name
mapply(sum, 6:9, c(5, NA, 3), 2:6, na.rm=TRUE)

# get the structure of rnorm
str(rnorm)

# mapply vectorizes both arguments "mean" and "sd"
mapply(rnorm, n=5, mean=me_ans, sd=std_devs)

# mapply vectorizes anonymous function
mapply(function(in_put, e_xp) in_put^e_xp, 1:5, seq(from=1, by=0.2, length.out=5))

# rnorm() vectorized with respect to "mean" and "sd", dealing with single value as well
vec_rnorm <- function(n, mean=0, sd=1) {
  if (length(mean)==1 && length(sd)==1)
    rnorm(n=n, mean=mean, sd=sd)
  else
    mapply(rnorm, n=n, mean=mean, sd=sd)
}

# call vec_rnorm() on vector of "sd"
vec_rnorm(n=2, sd=std_devs)

# call vec_rnorm() on vector of "mean"
vec_rnorm(n=2, mean=me_ans)
```

*** =sct
```{r}
success_msg("Vectorization gets higher dimension!")
```


--- type:NormalExercise lang:r xp:100 skills:1 key:944a839cd1
## Vectorized if-else Statements Using Function ifelse()

The function ifelse() performs vectorized if-else statements on vectors, ifelse() is much faster than performing an element-wise loop in R.

*** =instructions
- Use `ifelse()` for vectorized comparison.

*** =hint
Follow the instruction and introductions.

*** =pre_exercise_code
```{r}
# no pec
```

*** =sample_code
```{r}
# create two numeric vectors
vec_tor1 <- sin(0.25*pi*1:10)
vec_tor2 <- cos(0.25*pi*1:10)

# create third vector using 'ifelse'


# cbind all three together


# set plotting parameters
par(mar=c(7, 2, 1, 2), mgp=c(2, 1, 0),
    cex.lab=0.8, cex.axis=0.8, cex.main=0.8,
    cex.sub=0.5)

# plot matrix
matplot(type="l", lty="solid",
col=c("green", "blue", "red"), xlab="", ylab="")

# add legend
legend(title="", inset=0.05, cex=0.8, lwd=2,
       col=c("green", "blue", "red"))
```

*** =solution
```{r}
# create two numeric vectors
vec_tor1 <- sin(0.25*pi*1:10)
vec_tor2 <- cos(0.25*pi*1:10)

# create third vector using 'ifelse'
vec_tor3 <- ifelse(vec_tor1 > vec_tor2, vec_tor1, vec_tor2)

# cbind all three together
vec_tor4 <- cbind(vec_tor1, vec_tor2, vec_tor3)

# set plotting parameters
par(mar=c(7, 2, 1, 2), mgp=c(2, 1, 0),
    cex.lab=0.8, cex.axis=0.8, cex.main=0.8,
    cex.sub=0.5)

# plot matrix
matplot(vec_tor4, type="l", lty="solid",
col=c("green", "blue", "red"),
lwd=c(2, 2, 2), xlab="", ylab="")

# add legend
legend(x="bottomright", legend=colnames(vec_tor4),
       title="", inset=0.05, cex=0.8, lwd=2,
       lty=c(1, 1, 1), col=c("green", "blue", "red"))
```

*** =sct
```{r}
success_msg("Welcome to a colorful new world!")
```


--- type:NormalExercise lang:r xp:100 skills:1 key:75657a12ba
## Monte Carlo Simulation

Monte Carlo simulation consists of generating random samples from a given probability distribution, The Monte Carlo data samples can then used to calculate diﬀerent parameters of the probability distribution (moments, quantiles, etc.), and its functionals.

*** =instructions
- Generate large random numbers to simulate.

*** =hint
Follow the instruction and introductions.

*** =pre_exercise_code
```{r}
# no pec
```

*** =sample_code
```{r}
# reset random number generator
set.seed(1121)

# set length of simulated sample
sample_length <- 1000

# sample from Standard Normal Distribution


# sample mean - MC estimate


# sample standard deviation - MC estimate


# MC estimate of cumulative probability


# probability of values no bigger than 1


# frequency of less than 1


# MC estimate of 3rd quantile


# find the 75% value in sample

```

*** =solution
```{r}
# reset random number generator
set.seed(1121)

# set length of simulated sample
sample_length <- 1000

# sample from Standard Normal Distribution
sam_ple <- rnorm(sample_length)

# sample mean - MC estimate
mean(sam_ple)

# sample standard deviation - MC estimate
sd(sam_ple)

# MC estimate of cumulative probability
sam_ple <- sort(sam_ple)

# probability of values no bigger than 1
pnorm(1)

# frequency of less than 1
sum(sam_ple<1)/sample_length

# MC estimate of 3rd quantile
qnorm(0.75)

# find the 75% value in sample
sam_ple[0.75*sample_length]
```

*** =sct
```{r}
success_msg("Congrats! Monte Carlo starts with random value!")
```


--- type:NormalExercise lang:r xp:100 skills:1 key:a974740ed7
## Simulating Brownian Motion Using while() Loops

while() loops are often used in simulations, when the number of required loops is unknown in advance.

*** =instructions
- Use `while()` loop for specific conditions.

*** =hint
Follow the instruction and introductions.

*** =pre_exercise_code
```{r}
# no pec
```

*** =sample_code
```{r}
# reset random number generator
set.seed(1121)

# barrier level
lev_el <- 20

# number of simulation steps
len_gth <- 1000

# allocate path vector


# initialize path


# change the code to initialize simulation index
in_dex <- 0
while ((in_dex <= len_gth) &&
 (pa_th[in_dex - 1] < lev_el)) {
 
# change the code to simulate next step
  pa_th[in_dex] <- pa_th[in_dex - 1]
    
# change the code to advance in_dex
  in_dex <- in_dex
}

# fill remaining pa_th after it crosses lev_el


# create daily time series starting 2011


# create plot


# add horizontal line


# set title


# set other parameters
par(oma=c(1, 1, 1, 1), mgp=c(2, 1, 0), mar=c(5, 1, 1, 1), cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.5)
```

*** =solution
```{r}
# reset random number generator
set.seed(1121)

# barrier level
lev_el <- 20

# number of simulation steps
len_gth <- 1000

# allocate path vector
pa_th <- numeric(len_gth)

# initialize path
pa_th[1] <- 0

# change the code to initialize simulation index
in_dex <- 2
while ((in_dex <= len_gth) &&
 (pa_th[in_dex - 1] < lev_el)) {
 
# simulate next step
  pa_th[in_dex] <-
    pa_th[in_dex - 1] + rnorm(1)
    
# advance in_dex
  in_dex <- in_dex + 1
}

# fill remaining pa_th after it crosses lev_el
if (in_dex <= len_gth) pa_th[in_dex:len_gth] <- pa_th[in_dex - 1]

# create daily time series starting 2011
ts_var <- ts(data=pa_th, frequency=365, start=c(2011, 1))

# create plot
plot(ts_var, type="l", col="black", 
     lty="solid", xlab="", ylab="")

# add horizontal line
abline(h=lev_el, lwd=2, col="red")

# set title
title(main="Brownian motion crossing a barrier level", line=0.5)

# set other parameters
par(oma=c(1, 1, 1, 1), mgp=c(2, 1, 0), mar=c(5, 1, 1, 1), cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.5)
```

*** =sct
```{r}
success_msg("Hooray! Your first simulated stock path is produced!")
```


--- type:NormalExercise lang:r xp:100 skills:1 key:2f39aa9fee
## Simulating Brownian Motion Using Vectorized Functions

Simulations in R can be accelerated by pre-computing a vector of random numbers, instead of generatng them one at a time in a loop, Vectors of random numbers allow using vectorized functions, instead of ineﬃcient (slow) while() loops

*** =instructions
- Use vectorized function to speed up your simulation.

*** =hint
Follow the instruction and introductions.

*** =pre_exercise_code
```{r}
# no pec
```

*** =sample_code
```{r}
# reset random number generator
set.seed(1121)

# barrier level
lev_el <- 20

# number of simulation steps
len_gth <- 1000

# simulate path of Brownian motion


# find index when pa_th crosses lev_el


# fill remaining pa_th after it crosses lev_el


# create daily time series starting 2011


# create plot with horizontal line


# add horizontal line


# create title

```

*** =solution
```{r}
# reset random number generator
set.seed(1121)

# barrier level
lev_el <- 20

# number of simulation steps
len_gth <- 1000

# simulate path of Brownian motion
pa_th <- cumsum(rnorm(len_gth))

# find index when pa_th crosses lev_el
cro_ss <- which(pa_th > lev_el)

# fill remaining pa_th after it crosses lev_el
if (length(cro_ss)>0) {
  pa_th[(cro_ss[1]+1):len_gth] <-pa_th[cro_ss[1]]
}

# create daily time series starting 2011
ts_var <- ts(data=pa_th, frequency=365, start=c(2011, 1))

# create plot with horizontal line
plot(ts_var, type="l", col="black", lty="solid", xlab="", ylab="")

# add horizontal line
abline(h=lev_el, lwd=2, col="red")

# create title
title(main="Brownian motion crossing a barrier level", line=0.5)
```

*** =sct
```{r}
success_msg("Your first simulated stock path is even faster!")
```

--- type:NormalExercise lang:r xp:100 skills:1 key:3452f1b7d3
## Standard Errors of Estimators Using Bootstrap Simulation

The standard errors of estimators can be calculated using a bootstrap simulation.

The bootstrap procedure generates new data by randomly sampling with replacement from the observed data set.

The bootstrapped data is then used to re-calculate the estimator many times, producing a vector of values.

The bootstrapped estimator values can then be used to calculate the probability distribution of the estimator and its standard error.

Bootstrapping doesn’t provide accurate estimates for estimators that are sensitive to the ordering and correlations in the data.

*** =instructions
- Check if the simulated standard deviation is consistent to hypothesis.

*** =hint
Follow the instruction and introductions.

*** =pre_exercise_code
```{r}
# no pec
```

*** =sample_code
```{r}
# reset random number generator
set.seed(1121)

# number of simualated steps
sample_length <- 1000

# sample from Standard Normal Distribution


# sample mean


# sample standard deviation


# change the code to bootstrap of sample mean and median
boot_strap <- sapply(1:10000, function(x) {
  boot_sample <-
    sam_ple[sample_length, replace=TRUE]
  c(mean=mean(boot_sample),
    median=median(boot_sample))
})

# check first three result


# standard error from formula


# standard error of mean from bootstrap


# standard error of median from bootstrap

```

*** =solution
```{r}
# reset random number generator
set.seed(1121)

# number of simualated steps
sample_length <- 1000

# sample from Standard Normal Distribution
sam_ple <- rnorm(sample_length)

# sample mean
mean(sam_ple)

# sample standard deviation
sd(sam_ple)

# change the code to bootstrap of sample mean and median
boot_strap <- sapply(1:10000, function(x) {
  boot_sample <-
    sam_ple[sample.int(sample_length, replace=TRUE)]
  c(mean=mean(boot_sample),
    median=median(boot_sample))
})

# check first three result
boot_strap[, 1:3]

# standard error from formula
sd(sam_ple)/sqrt(sample_length)

# standard error of mean from bootstrap
sd(boot_strap["mean", ])

# standard error of median from bootstrap
sd(boot_strap["median", ])
```

*** =sct
```{r}
success_msg("Yes! The simulation has no problem with its variation!")
```

--- type:NormalExercise lang:r xp:100 skills:1 key:194a77a838
## Standard Errors of Regression Coeﬃcients Using Bootstrap

The standard errors of the regression coeﬃcients can be calculated using a bootstrap simulation.

The bootstrap procedure creates new design matrices by randomly sampling with replacement from the design matrix.

Regressions are performed on the bootstrapped design matrices, and the regression coeﬃcients are saved into a matrix of bootstrapped coeﬃcients.

*** =instructions
- Check the bootstrapped results!

*** =hint
Follow the instruction and introductions.

*** =pre_exercise_code
```{r}
# no pec
```

*** =sample_code
```{r}
# define explanatory variable
explana_tory <- rnorm(100, mean=2)

# produce random noise
noise <- rnorm(100)

# produce response variable


# define design matrix and regression formula


# produce formula


# change the code to bootstrap the regression
boot_strap <- sapply(1:100, function(x) {
  boot_sample <-
    sample(dim(design_matrix)[1], replace=TRUE)
  reg_model <- lm(reg_formula)
})
```

*** =solution
```{r}
# define explanatory variable
explana_tory <- rnorm(100, mean=2)

# produce random noise
noise <- rnorm(100)

# produce response variable
res_ponse <- -3 + explana_tory + noise

# define design matrix and regression formula
design_matrix <- data.frame(res_ponse, explana_tory)

# produce formula
reg_formula <- paste(colnames(design_matrix)[1],
  paste(colnames(design_matrix)[-1], collapse="+"),sep=" ~ ")

# change the code to bootstrap the regression
boot_strap <- sapply(1:100, function(x) {
  boot_sample <-
    sample.int(dim(design_matrix)[1], replace=TRUE)
  reg_model <- lm(reg_formula,
          data=design_matrix[boot_sample, ])
  reg_model$coefficients
})
```

*** =sct
```{r}
success_msg("Remember to see the result! Mont Carlo is powerful!")
```